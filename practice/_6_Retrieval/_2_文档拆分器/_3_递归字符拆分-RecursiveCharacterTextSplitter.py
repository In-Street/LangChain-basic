"""
	RecursiveCharacterTextSplitter :
			1. ä»¥ç‰¹å®šå­—ç¬¦è¿›è¡Œåˆ‡å‰²ï¼Œæä¾›åˆ‡å‰²çš„å­—ç¬¦åˆ—è¡¨ï¼Œé»˜è®¤    ["\n\n", "\n", " ", ""]

				é¦–å…ˆä»¥åˆ—è¡¨ä¸­ç¬¬ä¸€ä¸ªå­—ç¬¦è¿›è¡Œåˆ‡å‰²ï¼Œè‹¥åˆ‡å—å¤§äºchunk_sizeï¼Œåˆ™ä»¥åˆ—è¡¨ä¸­ç¬¬äºŒä¸ªå­—ç¬¦ç»§ç»­åˆ‡å‰²ï¼Œä»¥æ­¤ç±»æ¨ã€‚

			2.  ç‰¹ç‚¹ï¼š
					a. ä¿ç•™ä¸Šä¸‹æ–‡ï¼š ä¼˜å…ˆåœ¨è‡ªç„¶è¯­è¨€è¾¹ç•Œå¤„åˆ†å‰²ï¼Œå‡å°‘ä¿¡æ¯ç¢ç‰‡åŒ–ã€‚å¦‚æ®µè½ã€å¥å­ç»“å°¾
					b. é€šè¿‡é€’å½’å°è¯•å¤šç§åˆ†å‰²ç¬¦ï¼Œå°†æ–‡æœ¬åˆ†å‰²ä¸ºå¤§å°æ¥è¿‘chunk_size çš„ç‰‡æ®µ
					c. é€‚ç”¨äºå¤šç§æ–‡æœ¬ç±»å‹ï¼ˆä»£ç ã€Markdownã€æ™®é€šæ–‡æœ¬ï¼‰ï¼Œæ˜¯LangChain ä¸­æœ€å¸¸ç”¨çš„åˆ†å‰²å™¨
"""
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# ç¤ºä¾‹1:  ä½¿ç”¨ create_documents() åˆ‡å‰²
text = "LangChainæ¡†æ¶ç‰¹æ€§\n\nå¤šæ¨¡å‹é›†æˆ(GPT/Claude)\nè®°å¿†ç®¡ç†åŠŸèƒ½\né“¾å¼è°ƒç”¨è®¾è®¡ã€‚æ–‡æ¡£åˆ†æåœºæ™¯ç¤ºä¾‹ï¼šéœ€è¦å¤„ç†PDF/Wordç­‰æ ¼å¼ã€‚"
splitter = RecursiveCharacterTextSplitter(
	chunk_size=10,
	chunk_overlap=0,
	add_start_index=True
)
docs = splitter.create_documents([text])
for doc in docs:
	print(doc)
'''
	é€’å½’åˆ‡å‰²è¿‡ç¨‹ï¼š
			ç¬¬ä¸€é˜¶æ®µï¼š \n\né¡¶çº§åˆ†å‰²
				 å—1->  LangChainæ¡†æ¶ç‰¹æ€§   
				 å—2-> å¤šæ¨¡å‹é›†.... åç»­æ‰€ä»¥å†…å®¹
				 å—1 å’Œ å—2 çš„é•¿åº¦éƒ½å¤§äºchunk_size ï¼Œéœ€ç»§ç»­åˆ‡å‰²
			
			ç¬¬äºŒé˜¶æ®µï¼š\nåˆ†å‰² 	 
				å—1: æ— \n ç¬¦å·ï¼Œæ— ç©ºæ ¼ç¬¦å·ï¼ŒæŒ‰å­—ç¬¦åˆ†å‰²ï¼Œå¾—åˆ° ['L','a','n','g','C','h','a','i','n','æ¡†','æ¶','ç‰¹','æ€§']
						å‰chunk_sizeä¸ªå­—ç¬¦ï¼š LangChainæ¡†
						å‰©ä½™å­—ç¬¦ï¼š æ¶ç‰¹æ€§ 
						
				å—2: \n åˆ†å‰²ï¼Œå¾—åˆ°ï¼š  
						"å¤šæ¨¡å‹é›†æˆ(GPT/Claude)", # 17å­—ç¬¦  ï¼Œå¤§äºchunk_size ç»§ç»­åˆ‡å‰²ï¼Œæ— ç©ºæ ¼ ä»¥å­—ç¬¦åˆ‡åˆ†ä¸¤éƒ¨åˆ†ï¼š å¤šæ¨¡å‹é›†æˆ(GPT      /Claude)
						"è®°å¿†ç®¡ç†åŠŸèƒ½", # 6å­—ç¬¦ï¼Œæ— éœ€åˆ‡åˆ†
						"é“¾å¼è°ƒç”¨è®¾è®¡ã€‚æ–‡æ¡£åˆ†æåœºæ™¯ç¤ºä¾‹ï¼šéœ€è¦å¤„ç†PDF/Wordç­‰æ ¼å¼ã€‚" # 36å­—ç¬¦ï¼Œå¤§äºchunk_size ç»§ç»­åˆ‡å‰²ï¼Œæ— ç©ºæ ¼ ä»¥å­—ç¬¦åˆ‡åˆ†
'''
# 	è¾“å‡ºï¼š
# page_content='LangChainæ¡†' metadata={'start_index': 0}
# page_content='æ¶ç‰¹æ€§' metadata={'start_index': 10}
# page_content='å¤šæ¨¡å‹é›†æˆ(GPT' metadata={'start_index': 15}
# page_content='/Claude)' metadata={'start_index': 24}
# page_content='è®°å¿†ç®¡ç†åŠŸèƒ½' metadata={'start_index': 33}
# page_content='é“¾å¼è°ƒç”¨è®¾è®¡ã€‚æ–‡æ¡£' metadata={'start_index': 40}
# page_content='åˆ†æåœºæ™¯ç¤ºä¾‹ï¼šéœ€è¦å¤„' metadata={'start_index': 49}
# page_content='ç†PDF/Wordç­‰' metadata={'start_index': 59}
# page_content='æ ¼å¼ã€‚' metadata={'start_index': 69}


# ç¤ºä¾‹2:  ä½¿ç”¨ create_documents() æ–¹æ³•ï¼Œå°†æœ¬åœ°æ–‡ä»¶å†…å®¹åŠ è½½æˆå­—ç¬¦ä¸²åè¿›è¡Œåˆ‡å‰²
with open('../../resources/asset/load/08-ai.txt') as f:
	read_text = f.read()  # è¿”å›å­—ç¬¦ä¸²

splitter_2 = RecursiveCharacterTextSplitter(
	chunk_size=100,
	chunk_overlap=20,
)
doc_2 = splitter_2.create_documents([read_text])
for doc in doc_2:
	print(f'ğŸ”¥{doc.page_content}')

# ç¤ºä¾‹3: ä½¿ç”¨ split_documents() æ–¹æ³•ï¼Œåˆ©ç”¨ PyPDFLoader åŠ è½½æ–‡æ¡£ï¼Œå¯¹æ–‡æ¡£å†…å®¹åˆ‡å‰²
pdf_loader = PyPDFLoader(file_path='../../resources/asset/load/02-load.pdf')
list_docs = pdf_loader.load()  # è¿”å› list[Document]

splitter_3 = RecursiveCharacterTextSplitter(
	chunk_size=200,
	chunk_overlap=0,
	length_function=len,
)

docs_3 = splitter_3.split_documents(list_docs)
for doc in docs_3:
	print(f'{doc.page_content}')